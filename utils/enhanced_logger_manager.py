# utils/enhanced_logger_manager.py - Phi√™n b·∫£n c·∫£i thi·ªán
import logging
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import json
from io import StringIO
import threading
import time
from logging.handlers import TimedRotatingFileHandler
import gzip
import shutil
import signal
import atexit
import photoshop

class TaskLogHandler(logging.Handler):
    """Custom log handler ƒë·ªÉ thu th·∫≠p logs cho t·ª´ng task"""
    
    def __init__(self, task_id: str):
        super().__init__()
        self.task_id = task_id
        self.log_buffer = StringIO()
        self.task_logs = []
        self.lock = threading.RLock()  # S·ª≠ d·ª•ng RLock thay v√¨ Lock
        self.closed = False
        
    def emit(self, record):
        if self.closed:
            return
            
        try:
            with self.lock:
                if self.closed:  # Double check
                    return
                    
                log_entry = self.format(record)
                self.log_buffer.write(log_entry + '\n')
                
                # L∆∞u log v·ªõi metadata
                self.task_logs.append({
                    'timestamp': datetime.fromtimestamp(record.created).isoformat(),
                    'level': record.levelname,
                    'message': record.getMessage(),
                    'module': getattr(record, 'module', 'unknown'),
                    'funcName': getattr(record, 'funcName', 'unknown'),
                    'lineno': getattr(record, 'lineno', 0),
                    'task_id': self.task_id
                })
        except Exception as e:
            # Tr√°nh infinite loop n·∫øu logging b·ªã l·ªói
            print(f"Error in TaskLogHandler.emit: {e}")
    
    def get_logs(self) -> List[Dict[str, Any]]:
        """L·∫•y t·∫•t c·∫£ logs c·ªßa task hi·ªán t·∫°i"""
        if self.closed:
            return []
        try:
            with self.lock:
                return self.task_logs.copy()
        except:
            return []
    
    def get_logs_as_string(self) -> str:
        """L·∫•y logs d∆∞·ªõi d·∫°ng string"""
        if self.closed:
            return ""
        try:
            with self.lock:
                return self.log_buffer.getvalue()
        except:
            return ""
    
    def get_summary_message(self) -> str:
        """T·∫°o summary message ƒë·ªÉ g·ª≠i l√™n server"""
        if self.closed or not self.task_logs:
            return f"Task {self.task_id} completed"
            
        try:
            with self.lock:
                if not self.task_logs:
                    return f"Task {self.task_id} completed"
                
                summary_parts = []
                error_count = sum(1 for log in self.task_logs if log['level'] == 'ERROR')
                warning_count = sum(1 for log in self.task_logs if log['level'] == 'WARNING')
                info_count = sum(1 for log in self.task_logs if log['level'] == 'INFO')
                
                # Th√™m th·ªëng k√™
                summary_parts.append(f"üìä Logs: {len(self.task_logs)} entries")
                if error_count > 0:
                    summary_parts.append(f"‚ùå Errors: {error_count}")
                if warning_count > 0:
                    summary_parts.append(f"‚ö†Ô∏è Warnings: {warning_count}")
                if info_count > 0:
                    summary_parts.append(f"‚ÑπÔ∏è Info: {info_count}")
                
                # Th√™m log cu·ªëi c√πng
                last_log = self.task_logs[-1]
                last_message = last_log['message'][:100]
                if len(last_log['message']) > 100:
                    last_message += "..."
                summary_parts.append(f"üìù Last: {last_message}")
                
                return " | ".join(summary_parts)
        except Exception as e:
            return f"Task {self.task_id} completed with logging error: {str(e)}"
    
    def clear_logs(self):
        """X√≥a logs hi·ªán t·∫°i"""
        if self.closed:
            return
        try:
            with self.lock:
                self.log_buffer.truncate(0)
                self.log_buffer.seek(0)
                self.task_logs.clear()
        except:
            pass
    
    def close(self):
        """ƒê√≥ng handler"""
        try:
            with self.lock:
                self.closed = True
                if hasattr(self.log_buffer, 'close'):
                    self.log_buffer.close()
        except:
            pass
        super().close()

class SafeTimedRotatingFileHandler(TimedRotatingFileHandler):
    """Safe rotating handler v·ªõi error handling t·ªët h∆°n"""
    
    def __init__(self, filename, when='midnight', interval=1, backupCount=30, 
                 encoding=None, delay=False, utc=False, atTime=None):
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
        log_dir = os.path.dirname(filename)
        if log_dir and not os.path.exists(log_dir):
            os.makedirs(log_dir, exist_ok=True)
            
        super().__init__(filename, when, interval, backupCount, encoding, delay, utc, atTime)
        self.suffix = "%Y-%m-%d"
        
    def doRollover(self):
        """Override v·ªõi error handling t·ªët h∆°n"""
        try:
            # ƒê√≥ng file hi·ªán t·∫°i tr∆∞·ªõc khi rotate
            if self.stream:
                self.stream.close()
                self.stream = None
                 
            # G·ªçi rollover g·ªëc
            super().doRollover()
            
            # Compress v√† cleanup trong thread ri√™ng ƒë·ªÉ tr√°nh block
            threading.Thread(target=self._safe_maintenance, daemon=True).start()
            
        except Exception as e:
            # Log error nh∆∞ng kh√¥ng l√†m crash ·ª©ng d·ª•ng
            print(f"Error in log rotation: {e}")
            # C·ªë g·∫Øng m·ªü l·∫°i stream
            try:
                if not self.stream:
                    self.stream = self._open()
            except:
                pass
    
    def _safe_maintenance(self):
        """Th·ª±c hi·ªán compress v√† cleanup an to√†n"""
        try:
            self._compress_old_logs()
            self._cleanup_old_files()
        except Exception as e:
            print(f"Error in log maintenance: {e}")
    
    def _compress_old_logs(self):
        """N√©n c√°c file log c≈©"""
        try:
            log_dir = os.path.dirname(self.baseFilename)
            base_name = os.path.basename(self.baseFilename)
            
            if not os.path.exists(log_dir):
                return
                
            for file in os.listdir(log_dir):
                if (file.startswith(base_name) and 
                    not file.endswith('.gz') and 
                    file != base_name and
                    '.' in file):  # C√≥ extension date
                    
                    file_path = os.path.join(log_dir, file)
                    
                    # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i v√† c≈© h∆°n 1 ng√†y
                    if (os.path.exists(file_path) and 
                        os.path.getmtime(file_path) < time.time() - 86400):
                        
                        try:
                            with open(file_path, 'rb') as f_in:
                                with gzip.open(f"{file_path}.gz", 'wb') as f_out:
                                    shutil.copyfileobj(f_in, f_out)
                            os.remove(file_path)
                        except Exception as e:
                            print(f"Error compressing {file_path}: {e}")
                            
        except Exception as e:
            print(f"Error in compress_old_logs: {e}")
    
    def _cleanup_old_files(self):
        """D·ªçn d·∫πp file qu√° c≈© (>60 ng√†y)"""
        try:
            log_dir = os.path.dirname(self.baseFilename)
            base_name = os.path.basename(self.baseFilename)
            cutoff_time = time.time() - (60 * 86400)  # 60 ng√†y
            
            if not os.path.exists(log_dir):
                return
                
            for file in os.listdir(log_dir):
                if file.startswith(base_name) and file.endswith('.gz'):
                    file_path = os.path.join(log_dir, file)
                    try:
                        if (os.path.exists(file_path) and 
                            os.path.getmtime(file_path) < cutoff_time):
                            os.remove(file_path)
                    except Exception as e:
                        print(f"Error removing old file {file_path}: {e}")
                        
        except Exception as e:
            print(f"Error in cleanup_old_files: {e}")

class EnhancedLoggerManager:
    """Qu·∫£n l√Ω logging n√¢ng cao v·ªõi rotation theo ng√†y"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = log_dir
        self.task_handlers = {}
        self.task_loggers = {}
        self.lock = threading.RLock()
        self.shutdown_event = threading.Event()
        self._setup_directories()
        self._setup_main_logger()
        
        # Start cleanup thread
        self._start_cleanup_thread()
        
        # Register cleanup on exit
        atexit.register(self.shutdown)
        signal.signal(signal.SIGTERM, self._signal_handler)
        signal.signal(signal.SIGINT, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """Handle shutdown signals"""
        print(f"Received signal {signum}, shutting down logger manager...")
        self.shutdown()
    
    def shutdown(self):
        """Graceful shutdown"""
        print("Shutting down logger manager...")
        self.shutdown_event.set()
        
        # Cleanup all task loggers
        with self.lock:
            for task_id in list(self.task_handlers.keys()):
                try:
                    self.cleanup_task_logger(task_id)
                except:
                    pass
    
    def _setup_directories(self):
        """T·∫°o th∆∞ m·ª•c logs v·ªõi c·∫•u tr√∫c r√µ r√†ng"""
        directories = [
            self.log_dir,
            os.path.join(self.log_dir, "main"),
            os.path.join(self.log_dir, "tasks"),
            os.path.join(self.log_dir, "errors"),
            os.path.join(self.log_dir, "archived")
        ]
        
        for dir_path in directories:
            try:
                os.makedirs(dir_path, exist_ok=True)
            except Exception as e:
                print(f"Error creating directory {dir_path}: {e}")
    
    def _setup_main_logger(self):
        """Setup logger ch√≠nh v·ªõi daily rotation"""
        try:
            # Main log handler v·ªõi rotation h√†ng ng√†y
            main_handler = SafeTimedRotatingFileHandler(
                filename=os.path.join(self.log_dir, "main", "application.log"),
                when='midnight',
                interval=1,
                backupCount=30,
                encoding='utf-8'
            )
            main_handler.setLevel(logging.INFO)
            
            # Error log handler ri√™ng
            error_handler = SafeTimedRotatingFileHandler(
                filename=os.path.join(self.log_dir, "errors", "error.log"),
                when='midnight',
                interval=1,
                backupCount=60,  # Gi·ªØ error logs l√¢u h∆°n
                encoding='utf-8'
            )
            error_handler.setLevel(logging.ERROR)
            
            # Console handler
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            
            # Formatters
            detailed_formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(funcName)s() - %(message)s'
            )
            
            console_formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s'
            )
            
            main_handler.setFormatter(detailed_formatter)
            error_handler.setFormatter(detailed_formatter)
            console_handler.setFormatter(console_formatter)
            
            # Setup root logger
            root_logger = logging.getLogger()
            root_logger.setLevel(logging.INFO)
            
            # Clear existing handlers
            for handler in root_logger.handlers[:]:
                root_logger.removeHandler(handler)
            
            root_logger.addHandler(main_handler)
            root_logger.addHandler(error_handler)
            root_logger.addHandler(console_handler)
            
            # Prevent propagation to avoid duplication
            root_logger.propagate = False
            
        except Exception as e:
            print(f"Error setting up main logger: {e}")
    
    def create_task_logger(self, task_id: str) -> logging.Logger:
        """T·∫°o logger ri√™ng cho t·ª´ng task v·ªõi daily rotation"""
        with self.lock:
            logger_name = f"task_{task_id}"
            
            # N·∫øu logger ƒë√£ t·ªìn t·∫°i, tr·∫£ v·ªÅ lu√¥n
            if task_id in self.task_loggers:
                return self.task_loggers[task_id]
            
            try:
                task_logger = logging.getLogger(logger_name)
                task_logger.setLevel(logging.INFO)
                task_logger.propagate = False  # Kh√¥ng propagate l√™n root logger
                
                # T·∫°o custom handler cho task
                task_handler = TaskLogHandler(task_id)
                task_formatter = logging.Formatter(
                    '%(asctime)s - %(levelname)s - %(message)s'
                )
                task_handler.setFormatter(task_formatter)
                
                # File handler cho task v·ªõi daily rotation
                today = datetime.now().strftime("%Y-%m-%d")
                task_file_handler = SafeTimedRotatingFileHandler(
                    filename=os.path.join(self.log_dir, "tasks", f"task_{task_id}_{today}.log"),
                    when='midnight',
                    interval=1,
                    backupCount=7,  # Gi·ªØ task logs 7 ng√†y
                    encoding='utf-8'
                )
                task_file_handler.setFormatter(task_formatter)
                
                task_logger.addHandler(task_handler)
                task_logger.addHandler(task_file_handler)
                
                # L∆∞u references
                self.task_handlers[task_id] = task_handler
                self.task_loggers[task_id] = task_logger
                
                return task_logger
                
            except Exception as e:
                print(f"Error creating task logger for {task_id}: {e}")
                # Fallback to root logger
                return logging.getLogger()
    
    def get_task_logs(self, task_id: str) -> List[Dict[str, Any]]:
        """L·∫•y logs c·ªßa task"""
        if task_id in self.task_handlers:
            return self.task_handlers[task_id].get_logs()
        return []
    
    def get_task_logs_string(self, task_id: str) -> str:
        """L·∫•y logs c·ªßa task d∆∞·ªõi d·∫°ng string"""
        if task_id in self.task_handlers:
            return self.task_handlers[task_id].get_logs_as_string()
        return ""
    
    def get_task_summary_message(self, task_id: str) -> str:
        """L·∫•y summary message ƒë·ªÉ g·ª≠i l√™n server"""
        if task_id in self.task_handlers:
            return self.task_handlers[task_id].get_summary_message()
        return f"Task {task_id} completed"
    
    def clear_task_logs(self, task_id: str):
        """X√≥a logs c·ªßa task"""
        if task_id in self.task_handlers:
            self.task_handlers[task_id].clear_logs()
    
    def cleanup_task_logger(self, task_id: str):
        """D·ªçn d·∫πp logger c·ªßa task sau khi ho√†n th√†nh"""
        with self.lock:
            try:
                logger_name = f"task_{task_id}"
                
                if task_id in self.task_loggers:
                    task_logger = self.task_loggers[task_id]
                    
                    # X√≥a t·∫•t c·∫£ handlers
                    for handler in task_logger.handlers[:]:
                        handler.close()
                        task_logger.removeHandler(handler)
                    
                    # X√≥a t·ª´ dictionaries
                    del self.task_loggers[task_id]
                
                if task_id in self.task_handlers:
                    self.task_handlers[task_id].close()
                    del self.task_handlers[task_id]
                    
            except Exception as e:
                print(f"Error cleaning up task logger {task_id}: {e}")
    
    def _start_cleanup_thread(self):
        """Kh·ªüi ƒë·ªông thread d·ªçn d·∫πp t·ª± ƒë·ªông"""
        def cleanup_worker():
            while not self.shutdown_event.is_set():
                try:
                    # D·ªçn d·∫πp m·ªói gi·ªù
                    if self.shutdown_event.wait(3600):  # 1 hour or shutdown
                        break
                    self._periodic_cleanup()
                except Exception as e:
                    print(f"Error in cleanup thread: {e}")
        
        cleanup_thread = threading.Thread(target=cleanup_worker, daemon=True)
        cleanup_thread.start()
    
    def _periodic_cleanup(self):
        """D·ªçn d·∫πp ƒë·ªãnh k·ª≥"""
        try:
            # D·ªçn d·∫πp task loggers kh√¥ng s·ª≠ d·ª•ng
            with self.lock:
                # X√≥a c√°c task logger qu√° c≈© (>1 gi·ªù kh√¥ng ho·∫°t ƒë·ªông)
                current_time = time.time()
                to_remove = []
                
                for task_id, handler in self.task_handlers.items():
                    try:
                        # Ki·ªÉm tra th·ªùi gian log cu·ªëi c√πng
                        logs = handler.get_logs()
                        if logs:
                            last_log_time = datetime.fromisoformat(logs[-1]['timestamp']).timestamp()
                            if current_time - last_log_time > 3600:  # 1 gi·ªù
                                to_remove.append(task_id)
                        else:
                            # Kh√¥ng c√≥ logs, c√≥ th·ªÉ l√† task c≈©
                            to_remove.append(task_id)
                    except Exception as e:
                        print(f"Error checking task {task_id} for cleanup: {e}")
                        to_remove.append(task_id)
                
                for task_id in to_remove:
                    self.cleanup_task_logger(task_id)
                    
        except Exception as e:
            print(f"Error in periodic cleanup: {e}")
    
    def get_log_statistics(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ logging"""
        stats = {
            'active_tasks': len(self.task_handlers),
            'log_directories': [],
            'disk_usage': {}
        }
        
        try:
            # Th·ªëng k√™ th∆∞ m·ª•c
            for root, dirs, files in os.walk(self.log_dir):
                for dir_name in dirs:
                    dir_path = os.path.join(root, dir_name)
                    try:
                        if os.path.exists(dir_path):
                            file_count = len([f for f in os.listdir(dir_path) 
                                            if os.path.isfile(os.path.join(dir_path, f))])
                            total_size = sum(os.path.getsize(os.path.join(dir_path, f)) 
                                           for f in os.listdir(dir_path) 
                                           if os.path.isfile(os.path.join(dir_path, f)))
                            
                            stats['log_directories'].append({
                                'name': dir_name,
                                'path': dir_path,
                                'file_count': file_count,
                                'total_size_mb': round(total_size / (1024 * 1024), 2)
                            })
                    except Exception as e:
                        print(f"Error getting stats for {dir_path}: {e}")
        except Exception as e:
            print(f"Error getting log statistics: {e}")
        
        return stats

# Singleton instance
enhanced_logger_manager = EnhancedLoggerManager()

def get_task_logger(task_id: str) -> logging.Logger:
    """Helper function ƒë·ªÉ l·∫•y task logger"""
    return enhanced_logger_manager.create_task_logger(task_id)